{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e966a968",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import lightning as L\n",
    "import numpy as np\n",
    "import torch as th\n",
    "from lightning.pytorch import seed_everything\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics.classification.f_beta import F1Score\n",
    "from torchmetrics import MetricCollection\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from mamkit.configs.base import ConfigKey\n",
    "from mamkit.configs.text_audio import MMTransformerConfig\n",
    "from mamkit.data.collators import MultimodalCollator, TextTransformerCollator, AudioCollatorOutput\n",
    "from mamkit.data.datasets import MMUSEDFallacy, InputMode\n",
    "from mamkit.data.processing import MultimodalProcessor, AudioTransformer\n",
    "from mamkit.utility.callbacks import PycharmProgressBar\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c887acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_path = Path(__file__).parent.parent.resolve().joinpath('results', 'mmused-fallacy', 'afc', 'text_audio_late_fusion_logreg')\n",
    "save_path.mkdir(parents=True, exist_ok=True)\n",
    "base_data_path = Path(__file__).parent.parent.resolve().joinpath('data')\n",
    "\n",
    "loader = MMUSEDFallacy(task_name='afc',\n",
    "                       input_mode=InputMode.TEXT_AUDIO,\n",
    "                       base_data_path=base_data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70d27f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = MMTransformerConfig.from_config(key=ConfigKey(dataset='mmused-fallacy',\n",
    "                                                       input_mode=InputMode.TEXT_AUDIO,\n",
    "                                                       task_name='afc',\n",
    "                                                       tags={'anonymous', 'roberta', 'wav2vec2'}))\n",
    "\n",
    "config.audio_model_card = \"facebook/wav2vec2-base-960h\"\n",
    "config.processor_args['sampling_rate'] = 16000\n",
    "config.audio_model_args['sampling_rate'] = 16000\n",
    "\n",
    "trainer_args = {\n",
    "    'accelerator': 'auto',\n",
    "    'devices': 1,\n",
    "    'batch_size': 16,\n",
    "    'max_epochs': 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eea109f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_features_and_labels(dataloader, model):\n",
    "    model.eval()\n",
    "    features = []\n",
    "    labels = []\n",
    "    for batch in dataloader:\n",
    "        with th.no_grad():\n",
    "            text_features = model.model.encode_text(batch['text_input_ids'], batch['text_attention_mask'])\n",
    "            audio_features = model.model.encode_audio(batch['audio_features'])\n",
    "            fused_features = th.cat([text_features, audio_features], dim=1)\n",
    "            features.append(fused_features.cpu().numpy())\n",
    "            labels.append(batch['labels'].cpu().numpy())\n",
    "    return np.vstack(features), np.concatenate(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4d85e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metrics = {}\n",
    "for seed in config.seeds:\n",
    "    seed_everything(seed=seed)\n",
    "    for split_info in loader.get_splits(key='mm-argfallacy-2025'):\n",
    "        processor = MultimodalProcessor(audio_processor=AudioTransformer(\n",
    "            model_card=config.audio_model_card,\n",
    "            processor_args=config.processor_args,\n",
    "            model_args=config.audio_model_args,\n",
    "            aggregate=config.aggregate,\n",
    "            downsampling_factor=config.downsampling_factor,\n",
    "            sampling_rate=config.sampling_rate,\n",
    "            max_duration=5\n",
    "        ))\n",
    "        processor.fit(train_data=split_info.train)\n",
    "        split_info.train = processor(split_info.train)\n",
    "        split_info.val = processor(split_info.val)\n",
    "        split_info.test = processor(split_info.test)\n",
    "        processor.clear()\n",
    "\n",
    "        collator = MultimodalCollator(\n",
    "            text_collator=TextTransformerCollator(model_card=config.text_model_card,\n",
    "                                                  tokenizer_args=config.tokenizer_args),\n",
    "            audio_collator=AudioCollatorOutput(),\n",
    "            label_collator=lambda labels: th.tensor(labels)\n",
    "        )\n",
    "\n",
    "        train_dataloader = DataLoader(split_info.train, batch_size=config.batch_size, shuffle=False, collate_fn=collator)\n",
    "        val_dataloader = DataLoader(split_info.val, batch_size=config.batch_size, shuffle=False, collate_fn=collator)\n",
    "        test_dataloader = DataLoader(split_info.test, batch_size=config.batch_size, shuffle=False, collate_fn=collator)\n",
    "\n",
    "        model = MMTransformer(\n",
    "            model_card=config.text_model_card,\n",
    "            head=config.head,\n",
    "            is_transformer_trainable=config.is_transformer_trainable,\n",
    "            lstm_weights=config.lstm_weights,\n",
    "            audio_embedding_dim=config.audio_embedding_dim\n",
    "        )\n",
    "        model.eval()\n",
    "\n",
    "        X_train, y_train = extract_features_and_labels(train_dataloader, model)\n",
    "        X_val, y_val = extract_features_and_labels(val_dataloader, model)\n",
    "        X_test, y_test = extract_features_and_labels(test_dataloader, model)\n",
    "\n",
    "        clf = LogisticRegression(max_iter=1000, multi_class='multinomial')\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        y_val_pred = clf.predict(X_val)\n",
    "        y_test_pred = clf.predict(X_test)\n",
    "\n",
    "        val_f1 = f1_score(y_val, y_val_pred, average='macro')\n",
    "        test_f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "        logging.info(f'Seed {seed} | Validation F1: {val_f1:.4f} | Test F1: {test_f1:.4f}')\n",
    "\n",
    "        metrics.setdefault('validation', []).append(val_f1)\n",
    "        metrics.setdefault('test', []).append(test_f1)\n",
    "\n",
    "        processor.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee37851",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "val_avg = np.mean(metrics['validation'])\n",
    "val_std = np.std(metrics['validation'])\n",
    "test_avg = np.mean(metrics['test'])\n",
    "test_std = np.std(metrics['test'])\n",
    "\n",
    "summary = {\n",
    "    \"validation_avg\": val_avg,\n",
    "    \"validation_std\": val_std,\n",
    "    \"test_avg\": test_avg,\n",
    "    \"test_std\": test_std\n",
    "}\n",
    "\n",
    "logging.info(summary)\n",
    "np.save(save_path.joinpath('metrics.npy').as_posix(), summary)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
