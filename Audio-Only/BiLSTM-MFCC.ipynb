{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780c2acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import lightning as L\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import librosa\n",
    "from lightning.pytorch import seed_everything\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics.classification.f_beta import F1Score\n",
    "from torchmetrics import MetricCollection\n",
    "\n",
    "from mamkit.configs.audio import BiLSTMMFCCsConfig\n",
    "from mamkit.configs.base import ConfigKey\n",
    "from mamkit.data.collators import UnimodalCollator, AudioCollatorOutput\n",
    "from mamkit.data.datasets import MMUSEDFallacy, InputMode\n",
    "from mamkit.data.processing import UnimodalProcessor, MFCCExtractor\n",
    "from mamkit.models.audio import BiLSTM\n",
    "from mamkit.utility.callbacks import PycharmProgressBar\n",
    "from mamkit.utility.model import MAMKitLightingModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d74cab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "save_path = Path('results/mmused/afc/audio_only_lstm_mfcc')\n",
    "save_path.mkdir(parents=True, exist_ok=True)\n",
    "base_data_path = Path('data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79e2dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = MMUSEDFallacy(task_name='afc',\n",
    "                       input_mode=InputMode.AUDIO_ONLY,\n",
    "                       base_data_path=base_data_path)\n",
    "\n",
    "config = BiLSTMMFCCsConfig.from_config(key=ConfigKey(dataset='mmused-fallacy',\n",
    "                                                     input_mode=InputMode.AUDIO_ONLY,\n",
    "                                                     task_name='afc',\n",
    "                                                     tags='anonymous'))\n",
    "\n",
    "config.optimizer = th.optim.Adam\n",
    "config.optimizer_args = {'lr': 1e-3}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb11a7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_args = {\n",
    "    'accelerator': 'auto',\n",
    "    'devices': 1,\n",
    "    'batch_size': 8,\n",
    "    'max_epochs': 5,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92587896",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "for seed in config.seeds:\n",
    "    seed_everything(seed=seed)\n",
    "    for split_info in loader.get_splits(key='mm-argfallacy-2025'):\n",
    "        processor = UnimodalProcessor(features_processor=MFCCExtractor(\n",
    "            sampling_rate=16000,\n",
    "            normalize=True,\n",
    "            remove_energy=True,\n",
    "            pooling_sizes=config.pooling_sizes,\n",
    "            mfccs=13,\n",
    "            padding=True,\n",
    "            max_length=5 * 16000  # Standardize to 5 seconds\n",
    "        ))\n",
    "\n",
    "        processor.fit(split_info.train)\n",
    "        split_info.train = processor(split_info.train)\n",
    "        split_info.val = processor(split_info.val)\n",
    "        split_info.test = processor(split_info.test)\n",
    "        processor.clear()\n",
    "\n",
    "        unimodal_collator = UnimodalCollator(\n",
    "            features_collator=AudioCollatorOutput(),\n",
    "            label_collator=lambda labels: th.tensor(labels)\n",
    "        )\n",
    "\n",
    "        train_dataloader = DataLoader(split_info.train,\n",
    "                                      batch_size=config.batch_size,\n",
    "                                      shuffle=True,\n",
    "                                      collate_fn=unimodal_collator)\n",
    "        val_dataloader = DataLoader(split_info.val,\n",
    "                                    batch_size=config.batch_size,\n",
    "                                    shuffle=False,\n",
    "                                    collate_fn=unimodal_collator)\n",
    "        test_dataloader = DataLoader(split_info.test,\n",
    "                                     batch_size=config.batch_size,\n",
    "                                     shuffle=False,\n",
    "                                     collate_fn=unimodal_collator)\n",
    "\n",
    "        model = BiLSTM(embedding_dim=config.embedding_dim,\n",
    "                       lstm_weights=config.lstm_weights,\n",
    "                       head=config.head)\n",
    "        model = MAMKitLightingModel(model=model,\n",
    "                                    loss_function=config.loss_function,\n",
    "                                    num_classes=config.num_classes,\n",
    "                                    optimizer_class=config.optimizer,\n",
    "                                    val_metrics=MetricCollection({'f1': F1Score(task='multiclass', num_classes=6)}),\n",
    "                                    test_metrics=MetricCollection({'f1': F1Score(task='multiclass', num_classes=6)}),\n",
    "                                    **config.optimizer_args)\n",
    "\n",
    "        trainer = L.Trainer(**trainer_args,\n",
    "                            callbacks=[ModelCheckpoint(monitor='val_loss', mode='min'),\n",
    "                                       PycharmProgressBar()])\n",
    "        trainer.fit(model,\n",
    "                    train_dataloaders=train_dataloader,\n",
    "                    val_dataloaders=val_dataloader)\n",
    "\n",
    "        val_metrics = trainer.test(ckpt_path='best', dataloaders=val_dataloader)[0]\n",
    "        test_metrics = trainer.test(ckpt_path='best', dataloaders=test_dataloader)[0]\n",
    "        logging.info(f'Validation metrics: {val_metrics}')\n",
    "        logging.info(f'Test metrics: {test_metrics}')\n",
    "\n",
    "        for metric_name, metric_value in val_metrics.items():\n",
    "            metrics.setdefault('validation', {}).setdefault(metric_name, []).append(metric_value)\n",
    "        for metric_name, metric_value in test_metrics.items():\n",
    "            metrics.setdefault('test', {}).setdefault(metric_name, []).append(metric_value)\n",
    "\n",
    "        processor.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d313838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaging\n",
    "metric_names = list(metrics['validation'].keys())\n",
    "for split_name in ['validation', 'test']:\n",
    "    for metric_name in metric_names:\n",
    "        metric_values = np.array(metrics[split_name][metric_name]).reshape(len(config.seeds), -1)\n",
    "        per_seed_avg = metric_values.mean(axis=-1)\n",
    "        per_seed_std = metric_values.std(axis=-1)\n",
    "        avg = per_seed_avg.mean(axis=-1)\n",
    "        std = per_seed_avg.std(axis=-1)\n",
    "        metrics[split_name][f'per_seed_avg_{metric_name}'] = (per_seed_avg, per_seed_std)\n",
    "        metrics[split_name][f'avg_{metric_name}'] = (avg, std)\n",
    "\n",
    "logging.info(metrics)\n",
    "np.save(save_path.joinpath('metrics.npy').as_posix(), metrics)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
